{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meliksahb/Design-of-Intelligent-Machines-ME536-/blob/main/Week10_e2738425.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Full Name: Melikşah Beşir\n",
        "#Student ID: e2738425"
      ],
      "metadata": {
        "id": "vltmNTJUOO1A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try to Tell Apples, Oranges and else apart\n",
        "\n",
        "Images for this assignment are provided at github and they will be automatically downloaded right after imports. When the files are unzip there should be a folder:  ```AppleOrange```.\n",
        "These are sample images, you can test with more if you want. While testing just for fun, I can try other stuff as well.\n",
        "\n",
        "Your objective is to convert <font color=\"magenta\"> **Apples to magenta** </font>, <font color=\"blue\"> **Oranges to Blue** </font> , end blur everything else! While changing color, try to keep the original shading (i.e. try not provide a flat single color if possible, keep the shadings to the best you can).  \n",
        "\n",
        "<font color=\"red\">Do not be **too picky** and lose too much time</font>. Variety of images are provided so that you get the idea that generalizable / perfect filters are not easy to build. Yet your function is expected to work on more than one image at an acceptable level.  \n",
        "\n",
        "By the same token, you can use the ```fakes```, also for for fun to see how your algorighm works on unrealted images, and why a general filter is not that easy...  \n",
        "\n",
        "At the end as usual you are expected to **clear all outputs** and then save this file as **Week10_student_id.ipynb** and upload to the assignment at [ODTU Class](https://odtuclass2024f.metu.edu.tr/mod/assign/view.php?id=100364).  \n"
      ],
      "metadata": {
        "id": "EX3aiSdnOII7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# imports as usual\n",
        "You are only allowed to use concepts related to what we have seen in class and use only the following imports. You can import sub-libraries with new names etc. but NO NEW LIBRARIES"
      ],
      "metadata": {
        "id": "zLzqIVXJSCRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# not that all of them are necessary, but you are not allowed to import any new library\n",
        "# yet as before, you can import sub libraries: i.e.:\n",
        "#       from skimage import measure\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as pimg # check this out this is new\n",
        "from numpy import cos, arccos, sin, pi, round\n",
        "from numpy.linalg import matrix_rank as rank\n",
        "from numpy.linalg import svd, eig\n",
        "from scipy.linalg import orth\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "import cv2 as cv\n",
        "from sklearn.decomposition import PCA\n",
        "from skimage.segmentation import slic\n",
        "from skimage.util import img_as_float\n",
        "from skimage.color import rgb2lab\n",
        "from PIL import Image # good old pillow\n",
        "import sklearn as skl # famous sci-kit learn\n",
        "import skimage as ski # equally famous sci-kit image\n",
        "!rm bug_numpy_utils.py 2>/dev/null  # at the first run file does not exits but error should print\n",
        "!wget https://raw.githubusercontent.com/bugrakoku/bug_python_utils/main/bug_numpy_utils.py\n",
        "from bug_numpy_utils import MatPrint, CData, text2mat # note that once these files are downloaded you can read their content.\n",
        "!rm me536utils.py 2>/dev/null  # at the first run file does not exits but error should print\n",
        "!wget https://raw.githubusercontent.com/bugrakoku/bug_python_utils/main/me536utils.py\n",
        "from me536utils import RotMat\n",
        "import os"
      ],
      "metadata": {
        "id": "eQZIUC0gSQ7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## get images\n"
      ],
      "metadata": {
        "id": "K1-LOxSkVzxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm AppleOrange.zip 2>/dev/null # just in case\n",
        "!wget https://github.com/bugrakoku/data4all/raw/main/AppleOrange.zip # get the zip file\n",
        "!unzip AppleOrange.zip"
      ],
      "metadata": {
        "id": "35qHlbaGV47L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get prepared\n",
        "Below you can check images, perform tests runs, find critical color values etc.  \n",
        "Leave all your preparation code so that I can see how you have reached the final implementation of the function. This part I will NOT run for evaluation! I will only run the ```AorO()``` and ```AorO2()``` functions in my tests!  \n",
        "\n",
        "You can add as many code and text cells as you like below. But at the end, as I said above, I will just call the ```AorO()``` or ```AorO2()``` function.  \n",
        "And please **DO CLEAR ALL OUTPUTS**!\n",
        "\n",
        "Recall that you are not restricted to <font color=\"red\">R</font>\n",
        "<font color=\"green\">G</font>\n",
        "<font color=\"blue\">B</font> at all!"
      ],
      "metadata": {
        "id": "jREEYYBZS4vQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part I: Manual threshold determination.\n",
        "You can determine as many thresholds as you like.  \n"
      ],
      "metadata": {
        "id": "Aqe77tEeU-yz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add explanations of what you do and why regarding the code(s) below"
      ],
      "metadata": {
        "id": "mzpeYFNPFIys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ```AorO()``` function"
      ],
      "metadata": {
        "id": "x_rJGzeAVD0u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raXe6Vn6ODky"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "You are to properly implement the following function so that\n",
        "Apples become magenta, orange blue in color, and rest is blurred where blurring is visually detectable.\n",
        "\n",
        "'''\n",
        "\n",
        "def AorO(img):\n",
        "    '''\n",
        "    this function takes the path of an image, loads the image\n",
        "    converts the color of apples to magenta, color of oranges to blue and blurs the rest\n",
        "    you are to use some hand crafted thresholds here\n",
        "    returns the modified image\n",
        "    '''\n",
        "\n",
        "    # following is just a stub, you can totally get rid of it!\n",
        "    oi = pimg.imread(img) # read as RGB image\n",
        "    # Convert to HSV\n",
        "    hsv = cv.cvtColor(oi, cv.COLOR_RGB2HSV)\n",
        "    # hsv is in OpenCV format: H in [0,180), S,V in [0,255]\n",
        "    # reference: https://docs.opencv.org/4.x/df/d9d/tutorial_py_colorspaces.html\n",
        "    # Determining color spaces reference: https://www.hbmacit.com/2020/09/15/python-ve-opencv-ile-rgb-uzerinde-hsv-renk-kodu-tespiti/\n",
        "    # Red apples has two mask because H value is at the beginning of the angles:\n",
        "    # I asked GPT how to detect red/green/orange in image in hsv format\n",
        "    mask_red_lower = cv.inRange(hsv, (0,50,50), (10,255,255))\n",
        "    mask_red_upper = cv.inRange(hsv, (150,50,50), (180,255,255))\n",
        "    mask_red = cv.bitwise_or(mask_red_lower, mask_red_upper)\n",
        "\n",
        "    # Green apples: hue ~ [35,85]\n",
        "    mask_green = cv.inRange(hsv, (20,50,50), (85,255,255))\n",
        "\n",
        "    # Combine red and green apple masks\n",
        "    mask_apple = cv.bitwise_or(mask_red, mask_green)\n",
        "\n",
        "    # Orange: hue ~ [10,30]\n",
        "    mask_orange = cv.inRange(hsv, (10,50,50), (23,255,255))\n",
        "\n",
        "    # Combine fruit masks\n",
        "    mask_fruit = cv.bitwise_or(mask_apple, mask_orange)\n",
        "\n",
        "    # Blur the entire original image\n",
        "    blurred = cv.GaussianBlur(oi, (51,51), 0)\n",
        "    blurred_hsv = cv.cvtColor(blurred, cv.COLOR_RGB2HSV)\n",
        "\n",
        "    # Apples (red or green) -> magenta hue\n",
        "    # Magenta ~ 300 degrees => 300/2 = 150 in OpenCV hue\n",
        "    hue_apple = 150\n",
        "\n",
        "    # Oranges -> blue\n",
        "    # Blue ~ 240 degrees => 240/2 = 120 in OpenCV hue\n",
        "    hue_orange = 120\n",
        "\n",
        "    # Keep original S and V from oi\n",
        "    orig_s = hsv[:,:,1]\n",
        "    orig_v = hsv[:,:,2]\n",
        "\n",
        "    final_hsv = hsv.copy()\n",
        "\n",
        "    # For background (not fruit), use blurred HSV\n",
        "    # mask_fruit = 1 where fruit, 0 where background\n",
        "    # I asked GPT how to mask background instead of red/green and orange\n",
        "    background_mask = (mask_fruit == 0)\n",
        "    final_hsv[background_mask] = blurred_hsv[background_mask]\n",
        "\n",
        "    # Recolor apples\n",
        "    apple_locs = (mask_apple > 0)\n",
        "    final_hsv[apple_locs, 0] = hue_apple\n",
        "    final_hsv[apple_locs, 1] = orig_s[apple_locs]\n",
        "    final_hsv[apple_locs, 2] = orig_v[apple_locs]\n",
        "\n",
        "    # Recolor oranges\n",
        "    orange_locs = (mask_orange > 0)\n",
        "    final_hsv[orange_locs, 0] = hue_orange\n",
        "    final_hsv[orange_locs, 1] = orig_s[orange_locs]\n",
        "    final_hsv[orange_locs, 2] = orig_v[orange_locs]\n",
        "\n",
        "    # Convert back to RGB and scale to [0,1]\n",
        "    # I asked how to convert hsv to RGB\n",
        "    final_img = cv.cvtColor(final_hsv, cv.COLOR_HSV2RGB).astype(np.float32)/255.0\n",
        "\n",
        "\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(10,5))\n",
        "    ax[0].imshow(oi)\n",
        "    ax[0].set_title(\"Original\")\n",
        "    ax[0].axis('off')\n",
        "\n",
        "    ax[1].imshow(final_img)\n",
        "    ax[1].set_title(\"Processed\")\n",
        "    ax[1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return final_img\n",
        "\n",
        "# image_folder = '/content/AppleOrange'\n",
        "\n",
        "# for filename in os.listdir(image_folder):\n",
        "#     if filename.endswith(('.jpg', '.png')): # Process only image files\n",
        "#         image_path = os.path.join(image_folder, filename)\n",
        "#         processed_image = AorO(image_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function begins by loading the input image in RGB format and converting it to the HSV color space. I did this because HSV separates color information (hue) from intensity and brightness, making it easier and more accurate because hsv creates a sphere in 3D space and represents colors more precisely.\n",
        "\n",
        "Next, I created masks to identify the regions corresponding to apples and oranges. Apples were split into red and green varieties due to differences in their hue ranges, and the two masks were combined into a single apple mask. Oranges were similarly identified based on their hue values, and all the fruit masks were merged to distinguish fruit areas from the background.\n",
        "\n",
        "To visually separate the background from the fruits, I applied a Gaussian blur to the entire image. This blurred version is used for areas not covered by the fruit masks, ensuring that the fruits remain sharp and prominent while the background is de-emphasized.\n",
        "\n",
        "For recoloring, I changed the hue of apples to magenta (hue = 150) and oranges to blue (hue = 120). This transformation preserves the original saturation and brightness of these regions to maintain realistic visual effects. The blurred background is combined with the recolored fruits to produce the final image.\n",
        "\n",
        "Finally, I converted the modified image back to the RGB format for standard visualization and displayed both the original and processed images side by side. This approach highlights the fruits effectively by altering their colors while softening the background for better visual emphasis."
      ],
      "metadata": {
        "id": "gk1OjTY-W0sq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part II: Use some clustering methods to find thresholds automatically\n",
        "Assuming that there are apples and oranges in the image, analyze the colors in the image (such as histograms, or anything else you find fit), run some clustering algorithms on them and generate the image."
      ],
      "metadata": {
        "id": "oP7Phy3HDjyy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add explanations of what you do and why regarding the code(s) below"
      ],
      "metadata": {
        "id": "A5AMHo0cFQSx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ```AorO2()``` function"
      ],
      "metadata": {
        "id": "osrOY4fpE8Lz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "You are to properly implement the following function so that\n",
        "Apples become magenta, orange blue in color, and rest is blurred where blurring is visually detectable.\n",
        "\n",
        "'''\n",
        "\n",
        "def AorO2(img):\n",
        "    '''\n",
        "    This function takes the path of an image, loads the image,\n",
        "    converts the color of apples to magenta, color of oranges to blue and blurs the rest\n",
        "    using clustering thresholds.\n",
        "    Returns the modified image.\n",
        "    '''\n",
        "    # Load the image\n",
        "    oi = cv.imread(img)  # Reads the image in BGR format\n",
        "\n",
        "    # Convert the image to HSV color space\n",
        "    oi_hsv = cv.cvtColor(oi, cv.COLOR_BGR2HSV)\n",
        "\n",
        "    # Define HSV ranges for red (two ranges due to hue wrap-around), green, and orange\n",
        "    lower_red1 = np.array([0, 50, 50])\n",
        "    upper_red1 = np.array([10, 255, 255])\n",
        "    lower_red2 = np.array([165, 50, 50])\n",
        "    upper_red2 = np.array([180, 255, 255])\n",
        "\n",
        "    lower_green = np.array([20, 50, 50])\n",
        "    upper_green = np.array([85, 255, 255])\n",
        "\n",
        "    lower_orange = np.array([10, 100, 50])\n",
        "    upper_orange = np.array([23, 255, 255])\n",
        "\n",
        "    # Create masks for red, green, and orange\n",
        "    red_mask1 = cv.inRange(oi_hsv, lower_red1, upper_red1)\n",
        "    red_mask2 = cv.inRange(oi_hsv, lower_red2, upper_red2)\n",
        "    red_mask = cv.bitwise_or(red_mask1, red_mask2)  # Combine the two red masks\n",
        "\n",
        "    green_mask = cv.inRange(oi_hsv, lower_green, upper_green)\n",
        "    orange_mask = cv.inRange(oi_hsv, lower_orange, upper_orange)\n",
        "\n",
        "    # Combine red and green masks into one apple mask\n",
        "    apple_mask = cv.bitwise_or(red_mask, green_mask)\n",
        "\n",
        "    # Initialize the output image\n",
        "    output_img = np.copy(oi)\n",
        "\n",
        "    # Apply magenta color to apples\n",
        "    output_img[apple_mask > 0] = [255, 0, 255]  # Magenta in BGR\n",
        "\n",
        "    # Apply blue color to oranges\n",
        "    output_img[orange_mask > 0] = [255, 0, 0]  # Blue in BGR\n",
        "\n",
        "    # Blur the rest of the image\n",
        "    blurred_img = cv.GaussianBlur(oi, (51, 51), 0)\n",
        "    not_fruit_mask = ~(apple_mask > 0) & ~(orange_mask > 0)\n",
        "    output_img[not_fruit_mask] = blurred_img[not_fruit_mask]\n",
        "\n",
        "    return output_img\n",
        "\n",
        "# def plot_processed_images(image_folder, process_function):\n",
        "#     \"\"\"\n",
        "#     Plots the original and processed images side by side.\n",
        "\n",
        "#     Args:\n",
        "#         image_folder (str): Path to the folder containing the images.\n",
        "#         process_function (function): The function used to process the images.\n",
        "#     \"\"\"\n",
        "#     # List all image files in the folder\n",
        "#     image_files = [f for f in os.listdir(image_folder) if f.endswith(('.jpg', '.png'))]\n",
        "\n",
        "#     # Iterate over each image file\n",
        "#     for filename in image_files:\n",
        "#         image_path = os.path.join(image_folder, filename)\n",
        "\n",
        "#         # Read the original image\n",
        "#         original_image = cv.imread(image_path)\n",
        "#         original_image_rgb = cv.cvtColor(original_image, cv.COLOR_BGR2RGB)  # Convert to RGB for matplotlib\n",
        "\n",
        "#         # Process the image\n",
        "#         processed_image = process_function(image_path)\n",
        "#         processed_image_rgb = cv.cvtColor(processed_image, cv.COLOR_BGR2RGB)  # Convert to RGB for matplotlib\n",
        "\n",
        "#         # Plot original and processed images side by side\n",
        "#         plt.figure(figsize=(12, 6))\n",
        "#         plt.subplot(1, 2, 1)\n",
        "#         plt.imshow(original_image_rgb)\n",
        "#         plt.title('Original Image')\n",
        "#         plt.axis('off')\n",
        "\n",
        "#         plt.subplot(1, 2, 2)\n",
        "#         plt.imshow(processed_image_rgb)\n",
        "#         plt.title('Processed Image')\n",
        "#         plt.axis('off')\n",
        "\n",
        "#         plt.suptitle(f\"Image: {filename}\", fontsize=16)\n",
        "#         plt.show()\n",
        "\n",
        "# # Example usage:\n",
        "# image_folder = '/content/AppleOrange'\n",
        "\n",
        "# # Call the plotting function with the folder path and the processing function\n",
        "# plot_processed_images(image_folder, AorO2)"
      ],
      "metadata": {
        "id": "FUp5z6MHm730"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I started by loading the image using OpenCV and converting it from BGR to HSV color space because HSV is better suited for identifying specific colors. I defined thresholds for the HSV ranges to detect apples and oranges. I used two ranges for red because red wraps around the hue spectrum, and I included a green range to account for green apples. For oranges, I defined a separate range to detect their color. I then created masks.\n",
        "\n",
        "I combined the red and green masks to form an \"apple mask\" because both red and green pixels could represent apples. For oranges, I used the orange mask directly. I applied magenta ([255, 0, 255] in BGR) to the apple mask and blue ([255, 0, 0] in BGR) to the orange mask because these colors visually differentiate the fruits.\n",
        "\n",
        "To handle the rest of the image, I applied a Gaussian blur with a large kernel size to create a soft, visually detectable blur. I identified the areas not belonging to apples or oranges using logical negation of the masks. I then replaced those areas with the corresponding pixels from the blurred version of the original image."
      ],
      "metadata": {
        "id": "BtIpYnaikOtx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# My test will be performed below\n",
        "Using my own code either at the end of this file or separately on my computer, I will just call the  ```AorO()``` or ```AorO2() functions in different ways and enjoy the outcomes :)"
      ],
      "metadata": {
        "id": "v0fT5O_lDVvy"
      }
    }
  ]
}