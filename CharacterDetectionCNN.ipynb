{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/R+Sx/zqNVShqu9K4oYSl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meliksahb/Design-of-Intelligent-Machines-ME536-/blob/main/CharacterDetectionCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define characters and font\n",
        "CHARZ = ['B', 'U', 'D', 'R', 'K', 'A', 'E', '6', 'N']\n",
        "FONT_PATH = '/usr/share/fonts/truetype/liberation/LiberationMono-Bold.ttf'\n",
        "IMG_SIZE = 30  # Cell size\n",
        "fR = 0.8\n",
        "nB = int(IMG_SIZE*(1-fR))\n",
        "# Generate synthetic data\n",
        "def create_training_data(font_path, charz, img_size=30, num_samples_per_char=1000):\n",
        "    training_data = []\n",
        "    labels = []\n",
        "    for idx, char in enumerate(charz):\n",
        "        for _ in range(num_samples_per_char):\n",
        "            # Create an image with a single character\n",
        "            img = Image.new('RGB', (img_size, img_size), (255, 255, 255))\n",
        "            draw = ImageDraw.Draw(img)\n",
        "            font = ImageFont.truetype(font_path, size=np.random.randint(12, IMG_SIZE-1))\n",
        "            x_offset = int(np.random.rand()* nB)\n",
        "            y_offset = int(np.random.rand()* nB)\n",
        "            draw.text((x_offset, y_offset), char, font=font, fill=(0, 0, 0))\n",
        "\n",
        "            # Convert to grayscale and normalize\n",
        "            img_array = np.array(img.convert('L'))\n",
        "            training_data.append(img_array)\n",
        "            labels.append(idx)\n",
        "\n",
        "    training_data = np.array(training_data).reshape(-1, img_size, img_size, 1) / 255.0\n",
        "    labels = np.array(labels)\n",
        "    return training_data, labels\n",
        "\n",
        "# Generate training data\n",
        "X, y = create_training_data(FONT_PATH, CHARZ)\n",
        "\n",
        "# Split into train, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Build the CNN\n",
        "def build_cnn(input_shape=(30, 30, 1), num_classes=len(CHARZ)):\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Initialize the CNN\n",
        "model = build_cnn()\n",
        "\n",
        "# Train the CNN\n",
        "early_stopping = EarlyStopping(patience=5, restore_best_weights=True)\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
        "\n",
        "# # Display training history\n",
        "# plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "# plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "# Save the model\n",
        "model.save('character_recognition_model.h5')"
      ],
      "metadata": {
        "id": "27VMcumqxrc5",
        "outputId": "a9ef81d7-4fc6-4e0b-bbbd-549aa39e2088",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.4616 - loss: 1.5252 - val_accuracy: 0.9900 - val_loss: 0.1067\n",
            "Epoch 2/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.9932 - loss: 0.0662 - val_accuracy: 1.0000 - val_loss: 0.0207\n",
            "Epoch 3/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0120 - val_accuracy: 1.0000 - val_loss: 0.0063\n",
            "Epoch 4/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9998 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 0.0073\n",
            "Epoch 5/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 0.0021\n",
            "Epoch 6/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
            "Epoch 7/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 7.4793e-04 - val_accuracy: 1.0000 - val_loss: 8.9590e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 5.7021e-04 - val_accuracy: 1.0000 - val_loss: 7.1016e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 4.3161e-04 - val_accuracy: 1.0000 - val_loss: 5.5160e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 3.4041e-04 - val_accuracy: 1.0000 - val_loss: 4.1812e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.4692e-04 - val_accuracy: 1.0000 - val_loss: 3.5283e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.9840e-04 - val_accuracy: 1.0000 - val_loss: 3.4472e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.7054e-04 - val_accuracy: 1.0000 - val_loss: 3.0207e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.3734e-04 - val_accuracy: 1.0000 - val_loss: 2.4141e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.1007e-04 - val_accuracy: 1.0000 - val_loss: 1.6606e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 9.2929e-05 - val_accuracy: 1.0000 - val_loss: 1.6702e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 7.6496e-05 - val_accuracy: 1.0000 - val_loss: 1.2219e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 6.3499e-05 - val_accuracy: 1.0000 - val_loss: 1.0458e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 5.4047e-05 - val_accuracy: 1.0000 - val_loss: 9.0807e-05\n",
            "Epoch 20/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 4.5417e-05 - val_accuracy: 1.0000 - val_loss: 7.4263e-05\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3061e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from PIL import ImageColor\n",
        "\n",
        "\n",
        "# Define character set and colors\n",
        "CHARZ = ['B', 'U', 'D', 'R', 'K', 'A', 'E', '6', 'N']\n",
        "CHAR_COLORS = {\n",
        "    'B': \"pink\", 'U': \"yellow\", 'D': \"green\", 'R': \"orange\",\n",
        "    'K': \"red\", 'A': \"cyan\", 'E': \"magenta\", '6': \"blue\", 'N': \"purple\"\n",
        "}\n",
        "FONT_PATH = \"/usr/share/fonts/truetype/liberation/LiberationMono-Bold.ttf\"  # Adjust as needed\n",
        "\n",
        "# Load the saved CNN model\n",
        "model = load_model('/content/character_recognition_model.h5')\n",
        "\n",
        "\n",
        "\n",
        "# Function to preprocess test image and extract cells\n",
        "def preprocess_gen_image(img, cell_size=30):\n",
        "    \"\"\"\n",
        "    Preprocess the generated image to extract cells and their locations.\n",
        "    \"\"\"\n",
        "    img_array = np.array(img)\n",
        "    gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)\n",
        "    cells = []\n",
        "    locations = []\n",
        "    for y in range(0, img_array.shape[0], cell_size):\n",
        "        for x in range(0, img_array.shape[1], cell_size):\n",
        "            cell = gray[y:y+cell_size, x:x+cell_size]\n",
        "            if np.sum(cell < 255) > 10:  # Check for non-white pixels\n",
        "                cells.append(cell)\n",
        "                locations.append((x, y))\n",
        "    cells = np.array(cells).reshape(-1, cell_size, cell_size, 1) / 255.0\n",
        "    return cells, locations\n",
        "\n",
        "\n",
        "# Function to annotate and display results\n",
        "def annotate_image(img, locations, predictions, char_locations, cell_size=30):\n",
        "    \"\"\"\n",
        "    Annotate the image with predicted characters and colors.\n",
        "    \"\"\"\n",
        "    draw = ImageDraw.Draw(img)\n",
        "\n",
        "    img_array = np.array(img)\n",
        "    for (x, y), pred_idx in zip(locations, predictions):\n",
        "        char = CHARZ[pred_idx]\n",
        "        color = CHAR_COLORS[char]\n",
        "        # Color the rectangle without overwriting the character\n",
        "        draw.rectangle([x, y, x + cell_size, y + cell_size], outline=color, width=2)\n",
        "\n",
        "        # Convert color name to RGB\n",
        "        rgb_color = ImageColor.getrgb(color)\n",
        "\n",
        "       # Extract the region of interest (ROI) for the character\n",
        "        roi = img.crop((x, y, x + cell_size, y + cell_size))\n",
        "\n",
        "        # Convert the ROI to a numpy array for processing\n",
        "        roi_array = np.array(roi)\n",
        "\n",
        "        # Identify the pixels that belong to the character (non-white pixels)\n",
        "        mask = np.all(roi_array < [200, 200, 200], axis=-1)  # Adjust threshold as needed\n",
        "\n",
        "        # Apply the color to the detected character\n",
        "        roi_array[mask] = rgb_color  # Apply the color to the detected character\n",
        "\n",
        "        # Convert back to an image and paste it back into the original image\n",
        "        img.paste(Image.fromarray(roi_array), (x, y))\n",
        "\n",
        "        # Store the character's location\n",
        "        char_locations[char].append((x + cell_size / 2, y + cell_size / 2))\n",
        "\n",
        "# # Function to test the CNN on saved images\n",
        "# def test_saved_images(image_array, output_folder):\n",
        "\n",
        "#     char_locations = {char: [] for char in CHARZ}\n",
        "\n",
        "#     if not os.path.exists(output_folder):\n",
        "#         os.makedirs(output_folder)\n",
        "#     image = np.load(image_array)\n",
        "#     img = Image.fromarray(image.astype('uint8'))\n",
        "#     cells, locations = preprocess_gen_image(img)\n",
        "\n",
        "#     # Predict characters using the CNN\n",
        "#     predictions = np.argmax(model.predict(cells), axis=1)\n",
        "\n",
        "#     annotate_image(img, locations, predictions, char_locations)\n",
        "\n",
        "#     # Save the annotated image\n",
        "#     output_path = os.path.join(output_folder, \"annotated_image.png\")\n",
        "#     img.save(output_path)\n",
        "#     print(f\"Processed and saved: {output_path}\")\n",
        "\n",
        "#     return char_locations, img\n",
        "\n",
        "    # for img_path in image_paths:\n",
        "          # char_locations = {char: [] for char in CHARZ}\n",
        "\n",
        "    #     # Load the test image\n",
        "    #     img = np.load(img_path)\n",
        "    #     img = Image.fromarray(img.astype('uint8'))  # Convert to PIL Image\n",
        "\n",
        "    #     # Preprocess the image to extract cells and their locations\n",
        "    #     cells, locations = preprocess_gen_image(img)\n",
        "\n",
        "    #     # Predict characters using the CNN\n",
        "    #     predictions = np.argmax(model.predict(cells), axis=1)\n",
        "\n",
        "    #     annotate_image(img, locations, predictions, char_locations)\n",
        "\n",
        "    #     # Save the annotated image\n",
        "    #     output_path = os.path.join(output_folder, os.path.basename(img_path).replace('.npy', '_annotated.png'))\n",
        "    #     img.save(output_path)\n",
        "    #     print(f\"Processed and saved: {output_path}\")\n",
        "    #     # print(len(char_locations['K']))\n",
        "    #     return char_locations, annotate_image\n",
        "\n",
        "# # Paths to test images\n",
        "# image_folder = '/content/'\n",
        "# image_paths = [os.path.join(image_folder, fname) for fname in os.listdir(image_folder) if fname.endswith('.npy')]\n",
        "\n",
        "# # Output folder for annotated images\n",
        "# output_folder = \"/content/\"\n",
        "\n",
        "# # # Test on the saved images\n",
        "# # test_saved_images(image_paths, output_folder)\n",
        "\n",
        "# img = '/content/simpleF.npy'\n",
        "# test_saved_images(img, output_folder)\n"
      ],
      "metadata": {
        "id": "3b3IMJJnxtk8",
        "outputId": "547addd6-6f9a-4fba-bfbe-907a68b3aad2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def distance(p1, p2):\n",
        "    return math.hypot(p2[0] - p1[0], p2[1] - p1[1])\n",
        "\n",
        "def rotate90CW(x, y):\n",
        "    \"\"\"\n",
        "    Rotate the vector (x, y) by +90 degrees (clockwise).\n",
        "    Result: (y, -x).\n",
        "    \"\"\"\n",
        "    return (y, -x)\n",
        "\n",
        "def rotate90CCW(x, y):\n",
        "    \"\"\"\n",
        "    Rotate the vector (x, y) by -90 degrees (counter-clockwise).\n",
        "    Result: (-y, x).\n",
        "    \"\"\"\n",
        "    return (-y, x)\n",
        "\n",
        "def vector(p1, p2):\n",
        "    \"\"\"2D vector from p1 to p2.\"\"\"\n",
        "    return (p2[0] - p1[0], p2[1] - p1[1])\n",
        "\n",
        "def dot_product(v1, v2):\n",
        "    \"\"\"Dot product of two 2D vectors.\"\"\"\n",
        "    return v1[0]*v2[0] + v1[1]*v2[1]\n",
        "\n",
        "def is_perpendicular(p1, p2, p3, tol=1e-5):\n",
        "    \"\"\"\n",
        "    Check if the angle at p2 (formed by p2->p1 and p2->p3) is ~90 degrees.\n",
        "    \"\"\"\n",
        "    v1 = vector(p2, p1)\n",
        "    v2 = vector(p2, p3)\n",
        "    return abs(dot_product(v1, v2)) < tol\n",
        "\n",
        "def is_square(kpt, apt, rpt, ept, dist_tol=1e-5, angle_tol=1e-5):\n",
        "    \"\"\"\n",
        "    Checks if points (K, A, R, E) form a square in order K->A->R->E->K.\n",
        "    1) All sides ~ equal\n",
        "    2) All angles ~ 90 degrees\n",
        "    \"\"\"\n",
        "    dKA = distance(kpt, apt)\n",
        "    dAR = distance(apt, rpt)\n",
        "    dRE = distance(rpt, ept)\n",
        "    dEK = distance(ept, kpt)\n",
        "\n",
        "    sides = [dKA, dAR, dRE, dEK]\n",
        "    mean_side = sum(sides) / 4.0\n",
        "\n",
        "    # Check side lengths\n",
        "    for s in sides:\n",
        "        if abs(s - mean_side) > dist_tol:\n",
        "            return False\n",
        "\n",
        "    # Check angles at A, R, E, K\n",
        "    if (not is_perpendicular(kpt, apt, rpt, angle_tol) or\n",
        "        not is_perpendicular(apt, rpt, ept, angle_tol) or\n",
        "        not is_perpendicular(rpt, ept, kpt, angle_tol) or\n",
        "        not is_perpendicular(ept, kpt, apt, angle_tol)):\n",
        "        return False\n",
        "\n",
        "    return True\n",
        "\n",
        "def find_neighbors(letter_points, est_point, max_dist=3.0):\n",
        "    \"\"\"\n",
        "    Return all points in `letter_points` that are within `max_dist` of `est_point`.\n",
        "    \"\"\"\n",
        "    candidates = []\n",
        "    for p in letter_points:\n",
        "        if distance(p, est_point) <= max_dist:\n",
        "            candidates.append(p)\n",
        "    return candidates\n",
        "\n",
        "def find_best_square(k_points, a_points, r_points, e_points,\n",
        "                     dist_tol=1e-5, angle_tol=1e-5):\n",
        "    \"\"\"\n",
        "    Search all combos of K, A, R, E points, return the \"best\" square\n",
        "    (largest side). If none found, returns None.\n",
        "    \"\"\"\n",
        "    best_square_pts = None\n",
        "    best_side_len = 0.0\n",
        "\n",
        "    for kpt in k_points:\n",
        "        for apt in a_points:\n",
        "            for rpt in r_points:\n",
        "                for ept in e_points:\n",
        "                    if is_square(kpt, apt, rpt, ept, dist_tol, angle_tol):\n",
        "                        # Use distance(K, A) as side length\n",
        "                        side_len = distance(kpt, apt)\n",
        "                        if side_len > best_side_len:\n",
        "                            best_side_len = side_len\n",
        "                            best_square_pts = (kpt, apt, rpt, ept)\n",
        "\n",
        "    return best_square_pts\n",
        "\n",
        "def find_all_squares_kare_optimized(k_points, a_points, r_points, e_points,\n",
        "                                    dist_tol=1e-5, angle_tol=1e-5,\n",
        "                                    corner_tol=3.0):\n",
        "    \"\"\"\n",
        "    Return a list of *all* squares (K, A, R, E) that form a valid K->A->R->E->K\n",
        "    using the geometry approach:\n",
        "      - For each (K, A), compute the two possible corners R_est, E_est by rotating KA\n",
        "        +90° or -90° around A, and similarly around K.\n",
        "      - Find actual R in r_points near R_est, actual E in e_points near E_est.\n",
        "      - For each candidate, do a final is_square(...) check.\n",
        "    corner_tol = max distance in pixels to consider a point \"matching\" the computed corner.\n",
        "    \"\"\"\n",
        "    squares_found = []\n",
        "\n",
        "    for kpt in k_points:\n",
        "        for apt in a_points:\n",
        "            # Vector K->A\n",
        "            vx = apt[0] - kpt[0]\n",
        "            vy = apt[1] - kpt[1]\n",
        "            if abs(vx) < 1e-7 and abs(vy) < 1e-7:\n",
        "                # kpt == apt? skip\n",
        "                continue\n",
        "\n",
        "            # 1) CW orientation: rotate (K->A) by +90 deg around A => A->R\n",
        "            #    Also rotate (K->A) by +90 deg around K => K->E\n",
        "            #    Then R_est = A + rotate90CW(K->A)\n",
        "            #         E_est = K + rotate90CW(K->A)\n",
        "            vx_cw, vy_cw = rotate90CW(vx, vy)\n",
        "            r_est_cw = (apt[0] + vx_cw, apt[1] + vy_cw)\n",
        "            e_est_cw = (kpt[0] + vx_cw, kpt[1] + vy_cw)\n",
        "\n",
        "            # 2) CCW orientation: rotate (K->A) by -90 deg around A => A->R\n",
        "            #                     rotate (K->A) by -90 deg around K => K->E\n",
        "            vx_ccw, vy_ccw = rotate90CCW(vx, vy)\n",
        "            r_est_ccw = (apt[0] + vx_ccw, apt[1] + vy_ccw)\n",
        "            e_est_ccw = (kpt[0] + vx_ccw, kpt[1] + vy_ccw)\n",
        "\n",
        "            # Now find actual R points near r_est_cw, E points near e_est_cw, etc.\n",
        "            # We'll do for BOTH cw and ccw:\n",
        "            #    For each r in neighbors..., e in neighbors..., check is_square(k,a,r,e).\n",
        "\n",
        "            # Check CW\n",
        "            r_candidates_cw = find_neighbors(r_points, r_est_cw, corner_tol)\n",
        "            e_candidates_cw = find_neighbors(e_points, e_est_cw, corner_tol)\n",
        "            for rpt in r_candidates_cw:\n",
        "                for ept in e_candidates_cw:\n",
        "                    if is_square(kpt, apt, rpt, ept, dist_tol, angle_tol):\n",
        "                        squares_found.append((kpt, apt, rpt, ept))\n",
        "\n",
        "            # Check CCW\n",
        "            r_candidates_ccw = find_neighbors(r_points, r_est_ccw, corner_tol)\n",
        "            e_candidates_ccw = find_neighbors(e_points, e_est_ccw, corner_tol)\n",
        "            for rpt in r_candidates_ccw:\n",
        "                for ept in e_candidates_ccw:\n",
        "                    if is_square(kpt, apt, rpt, ept, dist_tol, angle_tol):\n",
        "                        squares_found.append((kpt, apt, rpt, ept))\n",
        "\n",
        "    return squares_found\n",
        "\n",
        "def draw_squares_pil(pil_image, squares, color='lime', width=3):\n",
        "    \"\"\"\n",
        "    squares is a list of (K, A, R, E) points.\n",
        "    Draw each square in order K->A->R->E->K.\n",
        "    \"\"\"\n",
        "    draw = ImageDraw.Draw(pil_image)\n",
        "    for (kpt, apt, rpt, ept) in squares:\n",
        "        kpt_i = (int(kpt[0]), int(kpt[1]))\n",
        "        apt_i = (int(apt[0]), int(apt[1]))\n",
        "        rpt_i = (int(rpt[0]), int(rpt[1]))\n",
        "        ept_i = (int(ept[0]), int(ept[1]))\n",
        "\n",
        "        draw.line([kpt_i, apt_i], fill=color, width=width)\n",
        "        draw.line([apt_i, rpt_i], fill=color, width=width)\n",
        "        draw.line([rpt_i, ept_i], fill=color, width=width)\n",
        "        draw.line([ept_i, kpt_i], fill=color, width=width)\n",
        "\n",
        "def build_letter_grid(height, width, cell_size, recognized_letters):\n",
        "    \"\"\"\n",
        "    Build a 2D array 'grid' of shape (rows, cols), where each element is\n",
        "    the recognized letter (like 'B','U','D','R', etc.) or '' if none.\n",
        "    - height, width: total pixel dimensions of the puzzle\n",
        "    - cell_size: e.g. 30\n",
        "    - recognized_letters: list of (letter, row, col) or dict structure\n",
        "      row, col are the grid coords, i.e. row = y//cell_size, col = x//cell_size\n",
        "    Returns: grid (list of lists), with shape = (rows, cols)\n",
        "    \"\"\"\n",
        "    rows = height // cell_size\n",
        "    cols = width // cell_size\n",
        "    grid = [['' for _ in range(cols)] for _ in range(rows)]\n",
        "\n",
        "    # recognized_letters might be something like:\n",
        "    # [ ('B', 0, 3), ('U', 0,4), ('D', 1,4), ... ]\n",
        "    # meaning row=0,col=3 has 'B', etc.\n",
        "    for (letter, r, c) in recognized_letters:\n",
        "        if 0 <= r < rows and 0 <= c < cols:\n",
        "            grid[r][c] = letter\n",
        "\n",
        "    return grid\n",
        "\n",
        "from collections import deque\n",
        "\n",
        "# 8 directions: N, NE, E, SE, S, SW, W, NW\n",
        "DIRS_8 = [(-1, 0), (-1, 1), (0, 1), (1, 1),\n",
        "          (1, 0), (1, -1), (0, -1), (-1, -1)]\n",
        "\n",
        "def bfs_8dir(grid, start_r, start_c, target_letter):\n",
        "    \"\"\"\n",
        "    BFS from (start_r, start_c) to find the nearest cell that has `target_letter`.\n",
        "    grid[r][c] is the letter in that cell or '' if none.\n",
        "    Returns (distance, path) if found, else (inf, None).\n",
        "\n",
        "    path is a list of (row, col) from start to target (inclusive).\n",
        "    \"\"\"\n",
        "    rows = len(grid)\n",
        "    cols = len(grid[0]) if rows > 0 else 0\n",
        "\n",
        "    # If the start cell itself has the target letter, path = [start].\n",
        "    if grid[start_r][start_c] == target_letter:\n",
        "        return (0, [(start_r, start_c)])\n",
        "\n",
        "    visited = [[False]*cols for _ in range(rows)]\n",
        "    visited[start_r][start_c] = True\n",
        "    parent = dict()  # to reconstruct path: parent[(r,c)] = (pr, pc)\n",
        "\n",
        "    queue = deque()\n",
        "    queue.append((start_r, start_c, 0))  # (row, col, distance)\n",
        "\n",
        "    while queue:\n",
        "        r, c, dist = queue.popleft()\n",
        "        # explore neighbors\n",
        "        for dr, dc in DIRS_8:\n",
        "            nr = r + dr\n",
        "            nc = c + dc\n",
        "            if 0 <= nr < rows and 0 <= nc < cols and not visited[nr][nc]:\n",
        "                visited[nr][nc] = True\n",
        "                parent[(nr, nc)] = (r, c)  # store how we reached (nr, nc)\n",
        "                # check if we've found the target\n",
        "                if grid[nr][nc] == target_letter:\n",
        "                    # reconstruct path\n",
        "                    path = [(nr, nc)]\n",
        "                    # backtrack\n",
        "                    cur = (nr, nc)\n",
        "                    while cur != (start_r, start_c):\n",
        "                        cur = parent[cur]\n",
        "                        path.append(cur)\n",
        "                    path.reverse()\n",
        "                    return (dist+1, path)\n",
        "                # else continue BFS\n",
        "                queue.append((nr, nc, dist+1))\n",
        "\n",
        "    return (float('inf'), None)  # not found\n",
        "\n",
        "def find_shortest_path_BUDUR_8dir(grid):\n",
        "    \"\"\"\n",
        "    Find the global shortest path that spells B->U->D->U->R in 8 directions.\n",
        "    Return (dist, full_path) if found, else (inf, None).\n",
        "\n",
        "    full_path is a list of (row, col).\n",
        "    \"\"\"\n",
        "    rows = len(grid)\n",
        "    cols = len(grid[0]) if rows>0 else 0\n",
        "\n",
        "    # 1) Collect all B positions\n",
        "    b_positions = []\n",
        "    for r in range(rows):\n",
        "        for c in range(cols):\n",
        "            if grid[r][c] == 'B':\n",
        "                b_positions.append((r, c))\n",
        "\n",
        "    # If no B, no path\n",
        "    if not b_positions:\n",
        "        return (float('inf'), None)\n",
        "\n",
        "    best_dist = float('inf')\n",
        "    best_path = None\n",
        "\n",
        "    # For each B, do BFS to find first U\n",
        "    for (br, bc) in b_positions:\n",
        "        distBU, pathBU = bfs_8dir(grid, br, bc, 'U')\n",
        "        if distBU == float('inf'):\n",
        "            continue  # can't find U from this B\n",
        "\n",
        "        # Now from that U, BFS to D\n",
        "        ur1, uc1 = pathBU[-1]  # the U we arrived at\n",
        "        distUD, pathUD = bfs_8dir(grid, ur1, uc1, 'D')\n",
        "        if distUD == float('inf'):\n",
        "            continue  # no D from this U\n",
        "\n",
        "        # From that D, BFS to a *different* U\n",
        "        dr, dc = pathUD[-1]\n",
        "        # We'll do a BFS for 'U', but if we land on the same (ur1, uc1), skip.\n",
        "        distU2, pathU2 = bfs_8dir(grid, dr, dc, 'U')\n",
        "        if distU2 == float('inf'):\n",
        "            continue\n",
        "\n",
        "        # Check if that U is different from the first U\n",
        "        ur2, uc2 = pathU2[-1]\n",
        "        if (ur2, uc2) == (ur1, uc1):\n",
        "            # We ended up on the same U, not allowed.\n",
        "            # (We can continue BFS until we find a different U,\n",
        "            #  but we'd have to modify bfs_8dir for that.)\n",
        "            continue\n",
        "\n",
        "        # Finally from that second U, BFS to R\n",
        "        distUR, pathUR = bfs_8dir(grid, ur2, uc2, 'R')\n",
        "        if distUR == float('inf'):\n",
        "            continue\n",
        "\n",
        "        # Combine all subpaths: B->U, U->D, D->U2, U2->R\n",
        "        total_dist = distBU + distUD + distU2 + distUR\n",
        "        if total_dist < best_dist:\n",
        "            best_dist = total_dist\n",
        "            # Build the full path by merging them carefully (avoiding duplication\n",
        "            # of the junction points)\n",
        "            # pathBU: B...U\n",
        "            # pathUD: U...D\n",
        "            # pathU2: D...U2\n",
        "            # pathUR: U2...R\n",
        "            full_path = (pathBU[:-1] +\n",
        "                         pathUD[:-1] +\n",
        "                         pathU2[:-1] +\n",
        "                         pathUR)\n",
        "            best_path = full_path\n",
        "\n",
        "    return (best_dist, best_path)\n",
        "\n",
        "def draw_path_pil(pil_image, path, color='blue', width=3):\n",
        "    \"\"\"\n",
        "    path is a list of (row, col) in grid coords.\n",
        "    We'll convert them to pixel coords if needed.\n",
        "    \"\"\"\n",
        "    if not path or len(path) < 2:\n",
        "        return\n",
        "\n",
        "    draw = ImageDraw.Draw(pil_image)\n",
        "\n",
        "    # Suppose each cell is cell_size x cell_size\n",
        "    # so the center of (row, col) is (col*cell_size + cell_size/2, row*cell_size + cell_size/2).\n",
        "    cell_size = 30\n",
        "    pix_pts = []\n",
        "    for (r, c) in path:\n",
        "        px = c*cell_size + cell_size/2\n",
        "        py = r*cell_size + cell_size/2\n",
        "        pix_pts.append((px, py))\n",
        "\n",
        "    # Draw lines from pix_pts[0]->pix_pts[1]->...\n",
        "    for i in range(len(pix_pts)-1):\n",
        "        draw.line([pix_pts[i], pix_pts[i+1]], fill=color, width=width)\n",
        "def build_grid_from_cnn(pil_img, model, cell_size=30):\n",
        "    \"\"\"\n",
        "    Given:\n",
        "      - pil_img: a PIL image of your puzzle (already loaded).\n",
        "      - model: your trained Keras model for character recognition.\n",
        "      - cell_size: size of each grid cell in pixels (e.g. 30).\n",
        "\n",
        "    Returns:\n",
        "      - grid (list of lists) of shape [rows][cols],\n",
        "        where grid[r][c] is the predicted character ('B','U','D','R','K','A','E','6','N', or '')\n",
        "        if no valid character is detected.\n",
        "\n",
        "    Notes:\n",
        "      - This function assumes each grid cell has *at most* one character.\n",
        "      - If you allow multiple chars per cell, you'll need a different approach.\n",
        "      - You can adapt the \"blank cell\" threshold as needed.\n",
        "    \"\"\"\n",
        "    import cv2\n",
        "    import numpy as np\n",
        "    from PIL import Image\n",
        "\n",
        "    # 1) Convert the PIL image to a NumPy array\n",
        "    img_array = np.array(pil_img)\n",
        "    height, width = img_array.shape[:2]\n",
        "\n",
        "    # 2) We'll build a 2D grid of size (rows, cols)\n",
        "    rows = height // cell_size\n",
        "    cols = width // cell_size\n",
        "\n",
        "    # The recognized characters (the same order used in your CNN training)\n",
        "    CHARZ = ['B','U','D','R','K','A','E','6','N']\n",
        "\n",
        "    # Create an empty grid filled with ''\n",
        "    grid = [['' for _ in range(cols)] for _ in range(rows)]\n",
        "\n",
        "    # Convert image to grayscale for CNN input\n",
        "    gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # 3) Iterate over each grid cell\n",
        "    for r in range(rows):\n",
        "        for c in range(cols):\n",
        "            # Pixel coords for this cell\n",
        "            y_start = r * cell_size\n",
        "            y_end   = y_start + cell_size\n",
        "            x_start = c * cell_size\n",
        "            x_end   = x_start + cell_size\n",
        "\n",
        "            # Extract the cell region\n",
        "            cell_gray = gray[y_start:y_end, x_start:x_end]\n",
        "\n",
        "            # Quick check if there's something in this cell\n",
        "            # (non-white area > some threshold)\n",
        "            if np.sum(cell_gray < 255) < 10:\n",
        "                # It's basically blank => store '' (empty)\n",
        "                grid[r][c] = ''\n",
        "                continue\n",
        "\n",
        "            # 4) Prepare the cell for CNN prediction\n",
        "            #    - reshape to (1, cell_size, cell_size, 1)\n",
        "            cell_norm = cell_gray.reshape(1, cell_size, cell_size, 1) / 255.0\n",
        "\n",
        "            # 5) Run the model to get prediction\n",
        "            pred = model.predict(cell_norm)  # shape (1, num_classes)\n",
        "            pred_idx = np.argmax(pred)       # which class index\n",
        "            predicted_char = CHARZ[pred_idx]\n",
        "\n",
        "            # 6) Store the predicted character in the grid\n",
        "            grid[r][c] = predicted_char\n",
        "\n",
        "    return grid"
      ],
      "metadata": {
        "id": "m6myyU1V-5Ce"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def SearchInAlphabetSoup(img, txt='KARE'):\n",
        "    \"\"\"\n",
        "    Given an image (numpy array) and a text (default 'KARE'),\n",
        "    - If txt == 'KARE', attempt to find centers of K, A, R, E that form a square.\n",
        "    - If found, draw the largest square on a copy of the image and return it.\n",
        "    - Otherwise, return the original or some other processed result for other words.\n",
        "    \"\"\"\n",
        "    # Convert the input array to PIL\n",
        "    pil_img = Image.fromarray(img.astype('uint8'))\n",
        "\n",
        "    # Preprocess => get cells + their top-left corners\n",
        "    cells, locations = preprocess_gen_image(pil_img)\n",
        "\n",
        "    # CNN predictions\n",
        "    predictions = np.argmax(model.predict(cells), axis=1)\n",
        "    cell_size=30\n",
        "    # We'll store locations for each recognized character\n",
        "    char_locations = {c: [] for c in CHARZ}\n",
        "    grid = build_grid_from_cnn(pil_img, model, cell_size)\n",
        "    # Annotate (color) each detected character in the PIL image\n",
        "    annotate_image(pil_img, locations, predictions, char_locations, cell_size=cell_size)\n",
        "\n",
        "    # If the user wants 'KARE', attempt to find the square\n",
        "    if txt.upper() == 'KARE':\n",
        "        k_points = char_locations['K']\n",
        "        a_points = char_locations['A']\n",
        "        r_points = char_locations['R']\n",
        "        e_points = char_locations['E']\n",
        "\n",
        "        if not (k_points and a_points and r_points and e_points):\n",
        "            print(\"Cannot form KARE because letters are missing.\")\n",
        "        else:\n",
        "            # Find *all* squares\n",
        "            squares = find_all_squares_kare_optimized(k_points, a_points,\n",
        "                                                      r_points, e_points,\n",
        "                                                      dist_tol=2,     # or small\n",
        "                                                      angle_tol=1e-3, # or small\n",
        "                                                      corner_tol=3.0) # neighbor radius\n",
        "            if squares:\n",
        "                print(f\"Found {len(squares)} KARE squares.\")\n",
        "                draw_squares_pil(pil_img, squares, color='lime', width=3)\n",
        "            else:\n",
        "                print(\"No valid KARE squares found.\")\n",
        "    elif txt.upper() == 'BUDUR':\n",
        "        dist_budur, path_budur = find_shortest_path_BUDUR_8dir(grid)\n",
        "        if dist_budur < float('inf'):\n",
        "            print(f\"Found BUDUR path with distance={dist_budur}\")\n",
        "            # Now draw that path on the PIL image\n",
        "            draw_path_pil(pil_img, path_budur, color='blue', width=3)\n",
        "        else:\n",
        "            print(\"No valid BUDUR path found (8-dir).\")\n",
        "    else:\n",
        "        # If you want to handle other words differently, do so here.\n",
        "        print(f\"No special square detection for '{txt}'.\")\n",
        "\n",
        "    # Return the annotated PIL image\n",
        "    return pil_img"
      ],
      "metadata": {
        "id": "NvK6p79C6Kb7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test codes -to be added to the end of your code\n",
        "# the SearchInAlphabetSoup() function you wrote will be called several times\n",
        "# during this test.\n",
        "\n",
        "# import for imread, just in case\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "from timeit import default_timer as timer\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import random\n",
        "\n",
        "# get the necessary file\n",
        "!rm *.jpg 2>/dev/null\n",
        "!wget https://raw.githubusercontent.com/bugrakoku/data4all/main/crashed.jpg\n",
        "\n",
        "\n",
        "\n",
        "def GenImage(numLetters = 50, fixedFontSize = True, xCount = 15, yCount = 10, pos = [], cvals = [] ):\n",
        "    '''\n",
        "    Input:\n",
        "        numLetters = maximum number of letters\n",
        "        fixedFontSize = well doug\n",
        "        xCount, yCount = number of rows and columns\n",
        "        pos and cvals = pre-allocated positions of characters\n",
        "\n",
        "    Output:\n",
        "        image as numpy array that contains letters randomly located\n",
        "    '''\n",
        "    # in the assignment assessment following will not change in test images\n",
        "    fontname = '/usr/share/fonts/truetype/liberation/LiberationMono-Bold.ttf'\n",
        "    cellSize = 30 #cell within which a single char will be printed\n",
        "    BackColor = (255,255, 255) # back color\n",
        "    ForeColor = (0, 0, 0) # font color\n",
        "    charz = ['B', 'U', 'D', 'R', 'K', 'A', 'E', '6', 'N']\n",
        "    # in the assignment assessment variable above will not change in generating test images\n",
        "    fR = 0.8 # font ratio to cell size\n",
        "    # generate an empty list to be filled in randomly\n",
        "    #charmap = [['' for i in range(xCount)] for j in range(yCount)] # assign\n",
        "\n",
        "    fontsize = int(cellSize * fR) # fixed font size\n",
        "    nB = int(cellSize*(1-fR)) # location noise\n",
        "\n",
        "    img = Image.new('RGB', (xCount*cellSize,yCount*cellSize), BackColor ) # blank image\n",
        "    imgPen = ImageDraw.Draw(img) # pen to draw on the blank image\n",
        "\n",
        "    # first generate random positions over pos\n",
        "    # note that pos might be already partially filled in\n",
        "    for i in range(len(pos), numLetters):\n",
        "        x = np.random.randint(0, xCount)\n",
        "        y = np.random.randint(0, yCount)\n",
        "        if [y,x] not in pos:\n",
        "            pos.append([y,x])\n",
        "            cvals.append(random.choice(charz))\n",
        "    print(f'size: {len(pos)}:{len(cvals)}')\n",
        "    # now that positions are determined, print random letters in them\n",
        "    for ([y,x], txt) in zip(pos, cvals): # draw each letter if random location is not already occupied, if occupied, skip\n",
        "        if not fixedFontSize: # if set so, select a random font size\n",
        "            fontsize = np.random.randint(12, cellSize-1)\n",
        "            dx, dy = 0, 0 # when scaled, position does not change\n",
        "        else: # add some location noise\n",
        "            dx = int(np.random.rand()* nB)\n",
        "            dy = int(np.random.rand()* nB)\n",
        "        font = ImageFont.truetype(fontname, fontsize) # font instace created\n",
        "        imgPen.text((x * cellSize + dx, y * cellSize + dy), txt, font=font, fill=ForeColor) # write the character to blank image\n",
        "\n",
        "\n",
        "    return np.array(img) # finally return image as an numpy array\n",
        "\n",
        "test_basic = ['simplest']\n",
        "test_more = ['simple', 'test50', 'test100']\n",
        "test_pro = ['test150', 'test250', 'test400', 'testInsane']\n",
        "test_all = test_basic + test_more + test_pro\n",
        "# the following are variable font size cases\n",
        "test_basicF = ['simplestF']\n",
        "test_moreF = ['simpleF', 'test50F', 'test100F']\n",
        "test_ProF = ['test150F', 'test250F', 'test400F', 'testInsaneF']\n",
        "test_allF = test_basicF + test_moreF + test_ProF\n",
        "\n",
        "def PerformTest(cases = ['simplest'], figSize = (25,25)):\n",
        "    shapes = ['KARE', 'BUDUR', '6KENAR']\n",
        "    crash = imread('crashed.jpg')\n",
        "    imgz = []\n",
        "    imgTitles = []\n",
        "    for case in cases:\n",
        "        img = np.load(f'{case}.npy')\n",
        "        for shape in shapes:\n",
        "            startTime = timer()\n",
        "            try:\n",
        "                print(f'Searching for {shape} in {case} ')\n",
        "                imgR = SearchInAlphabetSoup(img.copy(), shape)\n",
        "                imgz.append(imgR)\n",
        "            except:\n",
        "                imgz.append(crash)\n",
        "            endTime = timer()\n",
        "            imgTitles.append(f'{shape} in {case}: {round(endTime-startTime, 3)} sec.')\n",
        "            print(imgTitles[-1])\n",
        "\n",
        "    # finally plot the results\n",
        "    fig, axz = plt.subplots(len(imgz), 1, figsize=figSize)\n",
        "    for i, ax in enumerate(axz):\n",
        "        ax.imshow(imgz[i])\n",
        "        ax.set_title(imgTitles[i])\n",
        "\n",
        "# make suer the crashed image shows up\n",
        "# plt.imshow(plt.imread('crashed.jpg'))\n",
        "# plt.title('just checking the crash.jpg image... no worries yet...')"
      ],
      "metadata": {
        "id": "D4TsaO5kC49v",
        "outputId": "b44a15ea-e34f-49d0-c709-2caf6710dd66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-08 15:48:33--  https://raw.githubusercontent.com/bugrakoku/data4all/main/crashed.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14301 (14K) [image/jpeg]\n",
            "Saving to: ‘crashed.jpg’\n",
            "\n",
            "\rcrashed.jpg           0%[                    ]       0  --.-KB/s               \rcrashed.jpg         100%[===================>]  13.97K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-01-08 15:48:33 (23.0 MB/s) - ‘crashed.jpg’ saved [14301/14301]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# simplest case\n",
        "ch = ['K', 'A', 'R', 'E',\n",
        "      'B', 'U', 'D', 'U', 'R',\n",
        "      '6', 'K', 'E', 'N', 'A', 'R'\n",
        "]\n",
        "pos = [[0,9], [0,13], [4,13], [4, 9],\n",
        "        [5,0], [5,1], [5,2], [6,2], [7,2],\n",
        "        [10, 5], [7,7], [7,11], [10, 13 ], [13,11], [13,7],\n",
        "]\n",
        "img = GenImage(pos = pos.copy(), cvals=ch.copy(), xCount=20, yCount=20, numLetters=len(pos))\n",
        "imgF = GenImage(fixedFontSize=False, pos = pos.copy(), cvals=ch.copy(), xCount=20, yCount=20, numLetters=len(pos))\n",
        "np.save('simplest', img)\n",
        "np.save('simplestF', imgF)\n",
        "\n",
        "# simple case\n",
        "ch = ['K', 'A', 'R', 'E',\n",
        "      'A', 'R', 'E',\n",
        "      'B', 'U', 'D', 'U', 'R',\n",
        "      'U', 'A', 'R', 'K',\n",
        "      'R', 'D',\n",
        "      'K', '6', 'R',\n",
        "      '6', 'K', 'E', 'N', 'A', 'R'\n",
        "      ]\n",
        "pos = [[0,9], [0,18], [9,18], [9, 9],\n",
        "        [6, 18], [4, 11], [9, 12],\n",
        "        [5,0], [5,1], [5,2], [6,2], [7,2],\n",
        "        [6,0], [7,0], [9,0], [10,0],\n",
        "        [5,4], [5,5],\n",
        "        [6, 12], [10, 2], [14, 12] ]\n",
        "\n",
        "# add slightly randomized 6KENAR\n",
        "pos.append([np.random.randint(7, 17), 1]) #6\n",
        "pos.append([1, np.random.randint(0, 6)]) #K\n",
        "pos.append([1, np.random.randint(14, 20)]) #E\n",
        "pos.append([np.random.randint(4, 8), 19]) #N\n",
        "pos.append([np.random.randint(17, 20), 19]) #A\n",
        "pos.append([19, np.random.randint(5, 13)]) #R\n",
        "\n",
        "img = GenImage(pos = pos.copy(), cvals=ch.copy(), xCount=20, yCount=20, numLetters=len(pos))\n",
        "imgF = GenImage(fixedFontSize=False, pos = pos.copy(), cvals=ch.copy(), xCount=20, yCount=20, numLetters=len(pos))\n",
        "plt.imshow(img)\n",
        "np.save('simple', img)\n",
        "np.save('simpleF', imgF)\n",
        "\n",
        "\n",
        "# fixed font size cases\n",
        "img50 = GenImage(pos = pos.copy(), cvals=ch.copy(), xCount=20, yCount=20, numLetters=50)\n",
        "img100 = GenImage(pos = pos.copy(), cvals=ch.copy(), xCount=20, yCount=20, numLetters=100)\n",
        "img150 = GenImage(pos = pos.copy(), cvals=ch.copy(), xCount=20, yCount=20, numLetters=150)\n",
        "img250 = GenImage(pos = pos.copy(), cvals=ch.copy(), xCount=20, yCount=20, numLetters=250)\n",
        "img400 = GenImage(pos = pos.copy(), cvals=ch.copy(), xCount=20, yCount=20, numLetters=400)\n",
        "imgInsane = GenImage(pos = pos.copy(), cvals=ch.copy(), xCount=25, yCount=25, numLetters=3000)\n",
        "np.save('test50', img50)\n",
        "np.save('test100', img100)\n",
        "np.save('test150', img150)\n",
        "np.save('test250', img250)\n",
        "np.save('test400', img400)\n",
        "np.save('testInsane', imgInsane)\n",
        "\n",
        "# variable font size cases\n",
        "img50F = GenImage(fixedFontSize=False, pos = pos.copy(), cvals=ch.copy(), xCount=20, yCount=20, numLetters=50)\n",
        "img100F = GenImage(fixedFontSize=False, pos = pos.copy(), cvals=ch.copy(), xCount=20, yCount=20, numLetters=100)\n",
        "img150F = GenImage(fixedFontSize=False, pos = pos.copy(), cvals=ch.copy(), xCount=20, yCount=20, numLetters=150)\n",
        "img250F = GenImage(fixedFontSize=False, pos = pos.copy(), cvals=ch.copy(), xCount=20, yCount=20, numLetters=250)\n",
        "img400F = GenImage(fixedFontSize=False, pos = pos.copy(), cvals=ch.copy(), xCount=20, yCount=20, numLetters=400)\n",
        "imgInsaneF = GenImage(fixedFontSize=False, pos = pos.copy(), cvals=ch.copy(), xCount=25, yCount=25, numLetters=3000)\n",
        "np.save('test50F', img50F)\n",
        "np.save('test100F', img100F)\n",
        "np.save('test150F', img150F)\n",
        "np.save('test250F', img250F)\n",
        "np.save('test400F', img400F)\n",
        "np.save('testInsaneF', imgInsaneF)\n",
        "#'''"
      ],
      "metadata": {
        "id": "q0gl7qg0mydG",
        "outputId": "5a6bb50a-5c54-4021-cc69-67031a43ead4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size: 15:15\n",
            "size: 15:15\n",
            "size: 27:27\n",
            "size: 27:27\n",
            "size: 46:46\n",
            "size: 89:89\n",
            "size: 124:124\n",
            "size: 187:187\n",
            "size: 258:258\n",
            "size: 615:615\n",
            "size: 49:49\n",
            "size: 86:86\n",
            "size: 127:127\n",
            "size: 194:194\n",
            "size: 260:260\n",
            "size: 623:623\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fixed size font test\n",
        "# if you trust your code, test them all togather\n",
        "# or change the following to run one by one try it a few times you will get to the bottom of it\n",
        "#PerformTest(test_basic)\n",
        "PerformTest(test_all)"
      ],
      "metadata": {
        "id": "dDzJAtU1DUE3",
        "outputId": "851ce79a-0f94-4367-f54e-a69eb549f920",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching for KARE in simplest \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Found 1 KARE squares.\n",
            "KARE in simplest: 1.38 sec.\n",
            "Searching for BUDUR in simplest \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Found BUDUR path with distance=4\n",
            "BUDUR in simplest: 1.084 sec.\n",
            "Searching for 6KENAR in simplest \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "No special square detection for '6KENAR'.\n",
            "6KENAR in simplest: 1.07 sec.\n",
            "Searching for KARE in simple \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Found 1 KARE squares.\n",
            "KARE in simple: 1.978 sec.\n",
            "Searching for BUDUR in simple \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Found BUDUR path with distance=4\n",
            "BUDUR in simple: 2.031 sec.\n",
            "Searching for 6KENAR in simple \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "No special square detection for '6KENAR'.\n",
            "6KENAR in simple: 2.09 sec.\n",
            "Searching for KARE in test50 \n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# variable sized font tests\n",
        "PerformTest(test_allF)"
      ],
      "metadata": {
        "id": "Z8_WgkHGDgcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nMYH-KLmDoeG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}