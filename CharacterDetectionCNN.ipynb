{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzpyiseVHhwsrna1w/YYWb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meliksahb/Design-of-Intelligent-Machines-ME536-/blob/main/CharacterDetectionCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define characters and font\n",
        "CHARZ = ['B', 'U', 'D', 'R', 'K', 'A', 'E', '6', 'N']\n",
        "FONT_PATH = '/usr/share/fonts/truetype/liberation/LiberationMono-Bold.ttf'\n",
        "IMG_SIZE = 30  # Cell size\n",
        "fR = 0.8\n",
        "nB = int(IMG_SIZE*(1-fR))\n",
        "# Generate synthetic data\n",
        "def create_training_data(font_path, charz, img_size=30, num_samples_per_char=1000):\n",
        "    training_data = []\n",
        "    labels = []\n",
        "    for idx, char in enumerate(charz):\n",
        "        for _ in range(num_samples_per_char):\n",
        "            # Create an image with a single character\n",
        "            img = Image.new('RGB', (img_size, img_size), (255, 255, 255))\n",
        "            draw = ImageDraw.Draw(img)\n",
        "            font = ImageFont.truetype(font_path, size=np.random.randint(12, IMG_SIZE-1))\n",
        "            x_offset = int(np.random.rand()* nB)\n",
        "            y_offset = int(np.random.rand()* nB)\n",
        "            draw.text((x_offset, y_offset), char, font=font, fill=(0, 0, 0))\n",
        "\n",
        "            # Convert to grayscale and normalize\n",
        "            img_array = np.array(img.convert('L'))\n",
        "            training_data.append(img_array)\n",
        "            labels.append(idx)\n",
        "\n",
        "    training_data = np.array(training_data).reshape(-1, img_size, img_size, 1) / 255.0\n",
        "    labels = np.array(labels)\n",
        "    return training_data, labels\n",
        "\n",
        "# Generate training data\n",
        "X, y = create_training_data(FONT_PATH, CHARZ)\n",
        "\n",
        "# Split into train, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Build the CNN\n",
        "def build_cnn(input_shape=(30, 30, 1), num_classes=len(CHARZ)):\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Initialize the CNN\n",
        "model = build_cnn()\n",
        "\n",
        "# Train the CNN\n",
        "early_stopping = EarlyStopping(patience=5, restore_best_weights=True)\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
        "\n",
        "# # Display training history\n",
        "# plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "# plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "# Save the model\n",
        "model.save('character_recognition_model.h5')"
      ],
      "metadata": {
        "id": "27VMcumqxrc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from PIL import ImageColor\n",
        "\n",
        "\n",
        "# Define character set and colors\n",
        "CHARZ = ['B', 'U', 'D', 'R', 'K', 'A', 'E', '6', 'N']\n",
        "CHAR_COLORS = {\n",
        "    'B': \"pink\", 'U': \"yellow\", 'D': \"green\", 'R': \"orange\",\n",
        "    'K': \"red\", 'A': \"cyan\", 'E': \"magenta\", '6': \"blue\", 'N': \"purple\"\n",
        "}\n",
        "FONT_PATH = \"/usr/share/fonts/truetype/liberation/LiberationMono-Bold.ttf\"  # Adjust as needed\n",
        "\n",
        "# Load the saved CNN model\n",
        "model = load_model('/content/character_recognition_model.h5')\n",
        "\n",
        "\n",
        "\n",
        "# Function to preprocess test image and extract cells\n",
        "def preprocess_gen_image(img, cell_size=30):\n",
        "    \"\"\"\n",
        "    Preprocess the generated image to extract cells and their locations.\n",
        "    \"\"\"\n",
        "    img_array = np.array(img)\n",
        "    gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)\n",
        "    cells = []\n",
        "    locations = []\n",
        "    for y in range(0, img_array.shape[0], cell_size):\n",
        "        for x in range(0, img_array.shape[1], cell_size):\n",
        "            cell = gray[y:y+cell_size, x:x+cell_size]\n",
        "            if np.sum(cell < 255) > 10:  # Check for non-white pixels\n",
        "                cells.append(cell)\n",
        "                locations.append((x, y))\n",
        "    cells = np.array(cells).reshape(-1, cell_size, cell_size, 1) / 255.0\n",
        "    return cells, locations\n",
        "\n",
        "\n",
        "# Function to annotate and display results\n",
        "def annotate_image(img, locations, predictions, char_locations, cell_size=30):\n",
        "    \"\"\"\n",
        "    Annotate the image with predicted characters and colors.\n",
        "    \"\"\"\n",
        "    draw = ImageDraw.Draw(img)\n",
        "\n",
        "    img_array = np.array(img)\n",
        "    for (x, y), pred_idx in zip(locations, predictions):\n",
        "        char = CHARZ[pred_idx]\n",
        "        color = CHAR_COLORS[char]\n",
        "        # Color the rectangle without overwriting the character\n",
        "        draw.rectangle([x, y, x + cell_size, y + cell_size], outline=color, width=2)\n",
        "\n",
        "        # Convert color name to RGB\n",
        "        rgb_color = ImageColor.getrgb(color)\n",
        "\n",
        "       # Extract the region of interest (ROI) for the character\n",
        "        roi = img.crop((x, y, x + cell_size, y + cell_size))\n",
        "\n",
        "        # Convert the ROI to a numpy array for processing\n",
        "        roi_array = np.array(roi)\n",
        "\n",
        "        # Identify the pixels that belong to the character (non-white pixels)\n",
        "        mask = np.all(roi_array < [200, 200, 200], axis=-1)  # Adjust threshold as needed\n",
        "\n",
        "        # Apply the color to the detected character\n",
        "        roi_array[mask] = rgb_color  # Apply the color to the detected character\n",
        "\n",
        "        # Convert back to an image and paste it back into the original image\n",
        "        img.paste(Image.fromarray(roi_array), (x, y))\n",
        "\n",
        "        # Store the character's location\n",
        "        char_locations[char].append((x + cell_size / 2, y + cell_size / 2))\n",
        "\n",
        "# # Function to test the CNN on saved images\n",
        "# def test_saved_images(image_array, output_folder):\n",
        "\n",
        "#     char_locations = {char: [] for char in CHARZ}\n",
        "\n",
        "#     if not os.path.exists(output_folder):\n",
        "#         os.makedirs(output_folder)\n",
        "#     image = np.load(image_array)\n",
        "#     img = Image.fromarray(image.astype('uint8'))\n",
        "#     cells, locations = preprocess_gen_image(img)\n",
        "\n",
        "#     # Predict characters using the CNN\n",
        "#     predictions = np.argmax(model.predict(cells), axis=1)\n",
        "\n",
        "#     annotate_image(img, locations, predictions, char_locations)\n",
        "\n",
        "#     # Save the annotated image\n",
        "#     output_path = os.path.join(output_folder, \"annotated_image.png\")\n",
        "#     img.save(output_path)\n",
        "#     print(f\"Processed and saved: {output_path}\")\n",
        "\n",
        "#     return char_locations, img\n",
        "\n",
        "    # for img_path in image_paths:\n",
        "          # char_locations = {char: [] for char in CHARZ}\n",
        "\n",
        "    #     # Load the test image\n",
        "    #     img = np.load(img_path)\n",
        "    #     img = Image.fromarray(img.astype('uint8'))  # Convert to PIL Image\n",
        "\n",
        "    #     # Preprocess the image to extract cells and their locations\n",
        "    #     cells, locations = preprocess_gen_image(img)\n",
        "\n",
        "    #     # Predict characters using the CNN\n",
        "    #     predictions = np.argmax(model.predict(cells), axis=1)\n",
        "\n",
        "    #     annotate_image(img, locations, predictions, char_locations)\n",
        "\n",
        "    #     # Save the annotated image\n",
        "    #     output_path = os.path.join(output_folder, os.path.basename(img_path).replace('.npy', '_annotated.png'))\n",
        "    #     img.save(output_path)\n",
        "    #     print(f\"Processed and saved: {output_path}\")\n",
        "    #     # print(len(char_locations['K']))\n",
        "    #     return char_locations, annotate_image\n",
        "\n",
        "# # Paths to test images\n",
        "# image_folder = '/content/'\n",
        "# image_paths = [os.path.join(image_folder, fname) for fname in os.listdir(image_folder) if fname.endswith('.npy')]\n",
        "\n",
        "# # Output folder for annotated images\n",
        "# output_folder = \"/content/\"\n",
        "\n",
        "# # # Test on the saved images\n",
        "# # test_saved_images(image_paths, output_folder)\n",
        "\n",
        "# img = '/content/simpleF.npy'\n",
        "# test_saved_images(img, output_folder)\n"
      ],
      "metadata": {
        "id": "3b3IMJJnxtk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def distance(p1, p2):\n",
        "    \"\"\"Euclidean distance between p1=(x1,y1) and p2=(x2,y2).\"\"\"\n",
        "    return math.hypot(p2[0] - p1[0], p2[1] - p1[1])\n",
        "\n",
        "def vector(p1, p2):\n",
        "    \"\"\"2D vector from p1 to p2.\"\"\"\n",
        "    return (p2[0] - p1[0], p2[1] - p1[1])\n",
        "\n",
        "def dot_product(v1, v2):\n",
        "    \"\"\"Dot product of two 2D vectors.\"\"\"\n",
        "    return v1[0]*v2[0] + v1[1]*v2[1]\n",
        "\n",
        "def is_perpendicular(p1, p2, p3, tol=1e-5):\n",
        "    \"\"\"\n",
        "    Check if the angle at p2 (formed by p2->p1 and p2->p3) is ~90 degrees.\n",
        "    \"\"\"\n",
        "    v1 = vector(p2, p1)\n",
        "    v2 = vector(p2, p3)\n",
        "    return abs(dot_product(v1, v2)) < tol\n",
        "\n",
        "def is_square(kpt, apt, rpt, ept, dist_tol=1e-5, angle_tol=1e-5):\n",
        "    \"\"\"\n",
        "    Checks if points (K, A, R, E) form a square in order K->A->R->E->K.\n",
        "    1) All sides ~ equal\n",
        "    2) All angles ~ 90 degrees\n",
        "    \"\"\"\n",
        "    dKA = distance(kpt, apt)\n",
        "    dAR = distance(apt, rpt)\n",
        "    dRE = distance(rpt, ept)\n",
        "    dEK = distance(ept, kpt)\n",
        "\n",
        "    sides = [dKA, dAR, dRE, dEK]\n",
        "    mean_side = sum(sides) / 4.0\n",
        "\n",
        "    # Check side lengths\n",
        "    for s in sides:\n",
        "        if abs(s - mean_side) > dist_tol:\n",
        "            return False\n",
        "\n",
        "    # Check angles at A, R, E, K\n",
        "    if (not is_perpendicular(kpt, apt, rpt, angle_tol) or\n",
        "        not is_perpendicular(apt, rpt, ept, angle_tol) or\n",
        "        not is_perpendicular(rpt, ept, kpt, angle_tol) or\n",
        "        not is_perpendicular(ept, kpt, apt, angle_tol)):\n",
        "        return False\n",
        "\n",
        "    return True\n",
        "\n",
        "def find_best_square(k_points, a_points, r_points, e_points,\n",
        "                     dist_tol=1e-5, angle_tol=1e-5):\n",
        "    \"\"\"\n",
        "    Search all combos of K, A, R, E points, return the \"best\" square\n",
        "    (largest side). If none found, returns None.\n",
        "    \"\"\"\n",
        "    best_square_pts = None\n",
        "    best_side_len = 0.0\n",
        "\n",
        "    for kpt in k_points:\n",
        "        for apt in a_points:\n",
        "            for rpt in r_points:\n",
        "                for ept in e_points:\n",
        "                    if is_square(kpt, apt, rpt, ept, dist_tol, angle_tol):\n",
        "                        # Use distance(K, A) as side length\n",
        "                        side_len = distance(kpt, apt)\n",
        "                        if side_len > best_side_len:\n",
        "                            best_side_len = side_len\n",
        "                            best_square_pts = (kpt, apt, rpt, ept)\n",
        "\n",
        "    return best_square_pts\n",
        "\n",
        "def draw_square_pil(pil_image, square_pts, color='red', width=3):\n",
        "    \"\"\"\n",
        "    Draw lines for the square (K->A->R->E->K) using PIL.\n",
        "    Each point in `square_pts` is (x, y).\n",
        "    \"\"\"\n",
        "    draw = ImageDraw.Draw(pil_image)\n",
        "    kpt, apt, rpt, ept = square_pts\n",
        "\n",
        "    # Convert float coords to ints if necessary\n",
        "    kpt_i = (int(kpt[0]), int(kpt[1]))\n",
        "    apt_i = (int(apt[0]), int(apt[1]))\n",
        "    rpt_i = (int(rpt[0]), int(rpt[1]))\n",
        "    ept_i = (int(ept[0]), int(ept[1]))\n",
        "\n",
        "    # Draw lines\n",
        "    draw.line([kpt_i, apt_i], fill=color, width=width)\n",
        "    draw.line([apt_i, rpt_i], fill=color, width=width)\n",
        "    draw.line([rpt_i, ept_i], fill=color, width=width)\n",
        "    draw.line([ept_i, kpt_i], fill=color, width=width)"
      ],
      "metadata": {
        "id": "m6myyU1V-5Ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def SearchInAlphabetSoup(img, txt='KARE'):\n",
        "    \"\"\"\n",
        "    Given an image (numpy array) and a text (default 'KARE'),\n",
        "    - If txt == 'KARE', attempt to find centers of K, A, R, E that form a square.\n",
        "    - If found, draw the largest square on a copy of the image and return it.\n",
        "    - Otherwise, return the original or some other processed result for other words.\n",
        "    \"\"\"\n",
        "    # Convert the input array to PIL\n",
        "    pil_img = Image.fromarray(img.astype('uint8'))\n",
        "\n",
        "    # Preprocess => get cells + their top-left corners\n",
        "    cells, locations = preprocess_gen_image(pil_img)\n",
        "\n",
        "    # CNN predictions\n",
        "    predictions = np.argmax(model.predict(cells), axis=1)\n",
        "\n",
        "    # We'll store locations for each recognized character\n",
        "    char_locations = {c: [] for c in CHARZ}\n",
        "\n",
        "    # Annotate (color) each detected character in the PIL image\n",
        "    annotate_image(pil_img, locations, predictions, char_locations, cell_size=cell_size)\n",
        "\n",
        "    # If the user wants 'KARE', attempt to find the square\n",
        "    if txt.upper() == 'KARE':\n",
        "        k_centers = char_locations.get('K', [])\n",
        "        a_centers = char_locations.get('A', [])\n",
        "        r_centers = char_locations.get('R', [])\n",
        "        e_centers = char_locations.get('E', [])\n",
        "\n",
        "        # Only try if we have at least one of each\n",
        "        if k_centers and a_centers and r_centers and e_centers:\n",
        "            best_sq = find_best_square(k_centers, a_centers, r_centers, e_centers)\n",
        "            if best_sq is not None:\n",
        "                draw_square_pil(pil_img, best_sq, color='lime', width=3)\n",
        "                print(\"KARE square found:\", best_sq)\n",
        "            else:\n",
        "                print(\"No valid KARE square found.\")\n",
        "        else:\n",
        "            print(\"Cannot form KARE because one or more letters are missing.\")\n",
        "    else:\n",
        "        # If you want to handle other words differently, do so here.\n",
        "        print(f\"No special square detection for '{txt}'.\")\n",
        "\n",
        "    # Return the annotated PIL image\n",
        "    return pil_img"
      ],
      "metadata": {
        "id": "NvK6p79C6Kb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test codes -to be added to the end of your code\n",
        "# the SearchInAlphabetSoup() function you wrote will be called several times\n",
        "# during this test.\n",
        "\n",
        "# import for imread, just in case\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "from timeit import default_timer as timer\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import random\n",
        "\n",
        "# get the necessary file\n",
        "!rm *.jpg 2>/dev/null\n",
        "!wget https://raw.githubusercontent.com/bugrakoku/data4all/main/crashed.jpg\n",
        "\n",
        "\n",
        "\n",
        "def GenImage(numLetters = 50, fixedFontSize = True, xCount = 15, yCount = 10, pos = [], cvals = [] ):\n",
        "    '''\n",
        "    Input:\n",
        "        numLetters = maximum number of letters\n",
        "        fixedFontSize = well doug\n",
        "        xCount, yCount = number of rows and columns\n",
        "        pos and cvals = pre-allocated positions of characters\n",
        "\n",
        "    Output:\n",
        "        image as numpy array that contains letters randomly located\n",
        "    '''\n",
        "    # in the assignment assessment following will not change in test images\n",
        "    fontname = '/usr/share/fonts/truetype/liberation/LiberationMono-Bold.ttf'\n",
        "    cellSize = 30 #cell within which a single char will be printed\n",
        "    BackColor = (255,255, 255) # back color\n",
        "    ForeColor = (0, 0, 0) # font color\n",
        "    charz = ['B', 'U', 'D', 'R', 'K', 'A', 'E', '6', 'N']\n",
        "    # in the assignment assessment variable above will not change in generating test images\n",
        "    fR = 0.8 # font ratio to cell size\n",
        "    # generate an empty list to be filled in randomly\n",
        "    #charmap = [['' for i in range(xCount)] for j in range(yCount)] # assign\n",
        "\n",
        "    fontsize = int(cellSize * fR) # fixed font size\n",
        "    nB = int(cellSize*(1-fR)) # location noise\n",
        "\n",
        "    img = Image.new('RGB', (xCount*cellSize,yCount*cellSize), BackColor ) # blank image\n",
        "    imgPen = ImageDraw.Draw(img) # pen to draw on the blank image\n",
        "\n",
        "    # first generate random positions over pos\n",
        "    # note that pos might be already partially filled in\n",
        "    for i in range(len(pos), numLetters):\n",
        "        x = np.random.randint(0, xCount)\n",
        "        y = np.random.randint(0, yCount)\n",
        "        if [y,x] not in pos:\n",
        "            pos.append([y,x])\n",
        "            cvals.append(random.choice(charz))\n",
        "    print(f'size: {len(pos)}:{len(cvals)}')\n",
        "    # now that positions are determined, print random letters in them\n",
        "    for ([y,x], txt) in zip(pos, cvals): # draw each letter if random location is not already occupied, if occupied, skip\n",
        "        if not fixedFontSize: # if set so, select a random font size\n",
        "            fontsize = np.random.randint(12, cellSize-1)\n",
        "            dx, dy = 0, 0 # when scaled, position does not change\n",
        "        else: # add some location noise\n",
        "            dx = int(np.random.rand()* nB)\n",
        "            dy = int(np.random.rand()* nB)\n",
        "        font = ImageFont.truetype(fontname, fontsize) # font instace created\n",
        "        imgPen.text((x * cellSize + dx, y * cellSize + dy), txt, font=font, fill=ForeColor) # write the character to blank image\n",
        "\n",
        "\n",
        "    return np.array(img) # finally return image as an numpy array\n",
        "\n",
        "test_basic = ['simplest']\n",
        "test_more = ['simple', 'test50', 'test100']\n",
        "test_pro = ['test150', 'test250', 'test400', 'testInsane']\n",
        "test_all = test_basic + test_more + test_pro\n",
        "# the following are variable font size cases\n",
        "test_basicF = ['simplestF']\n",
        "test_moreF = ['simpleF', 'test50F', 'test100F']\n",
        "test_ProF = ['test150F', 'test250F', 'test400F', 'testInsaneF']\n",
        "test_allF = test_basicF + test_moreF + test_ProF\n",
        "\n",
        "def PerformTest(cases = ['simplest'], figSize = (25,25)):\n",
        "    shapes = ['KARE', 'BUDUR', '6KENAR']\n",
        "    crash = imread('crashed.jpg')\n",
        "    imgz = []\n",
        "    imgTitles = []\n",
        "    for case in cases:\n",
        "        img = np.load(f'{case}.npy')\n",
        "        for shape in shapes:\n",
        "            startTime = timer()\n",
        "            try:\n",
        "                print(f'Searching for {shape} in {case} ')\n",
        "                imgR = SearchInAlphabetSoup(img.copy(), shape)\n",
        "                imgz.append(imgR)\n",
        "            except:\n",
        "                imgz.append(crash)\n",
        "            endTime = timer()\n",
        "            imgTitles.append(f'{shape} in {case}: {round(endTime-startTime, 3)} sec.')\n",
        "            print(imgTitles[-1])\n",
        "\n",
        "    # finally plot the results\n",
        "    fig, axz = plt.subplots(len(imgz), 1, figsize=figSize)\n",
        "    for i, ax in enumerate(axz):\n",
        "        ax.imshow(imgz[i])\n",
        "        ax.set_title(imgTitles[i])\n",
        "\n",
        "# make suer the crashed image shows up\n",
        "# plt.imshow(plt.imread('crashed.jpg'))\n",
        "# plt.title('just checking the crash.jpg image... no worries yet...')"
      ],
      "metadata": {
        "id": "D4TsaO5kC49v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fixed size font test\n",
        "# if you trust your code, test them all togather\n",
        "# or change the following to run one by one try it a few times you will get to the bottom of it\n",
        "PerformTest(test_basic)\n",
        "#PerformTest(test_all)"
      ],
      "metadata": {
        "id": "dDzJAtU1DUE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# variable sized font tests\n",
        "PerformTest(test_allF)"
      ],
      "metadata": {
        "id": "Z8_WgkHGDgcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nMYH-KLmDoeG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}